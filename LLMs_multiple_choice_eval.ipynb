{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating LLMsâ€˜ Performance in Answering RD Exam Prep Questions\n",
    "This notebook provides code examples to get the questions from the database and ask the questions in batch to the LLMs. \n",
    "The LLMs evaluated in this project are:\n",
    "- GPT 4o\n",
    "- Gemini 1.5 Pro\n",
    "- Claude 3.5 - Sonnet\n",
    "\n",
    "## Setup\n",
    "Before running the rest of this notebook, you'll need to run the cells below to ensure necessary libaraies are installed. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install openai\n",
    "#%pip install boto3\n",
    "#%pip install -q -U google-generativeai\n",
    "#%pip install tenacity\n",
    "#%pip install pymysql\n",
    "#%pip install sqlalchemy\n",
    "#%pip install pandas\n",
    "#%pip install sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to store your enviromental variables in the .env file.\n",
    "Here is the sample .env file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MYSQL_USER=<Your_MySQL_User>\n",
    "MYSQL_PASSWORD=<Your_MySQL_Password>\n",
    "MYSQL_HOST=<Your_MySQL_Host>\n",
    "MYSQL_PORT=<Your_MySQL_Port>\n",
    "DB_NAME=<Your_Database_Name>\n",
    "OPENAI_API_KEY=<Your_OPENAI_API_Key>\n",
    "GEMINI_API_KEY=<Your_GEMINI_API_Key>\n",
    "GOOGLE_CLOUD_PROJECT=<Your_Google_Cloud_Project_ID>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will also need to set AWS access. Please follow the instruction here: https://boto3.amazonaws.com/v1/documentation/api/latest/guide/quickstart.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to the LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to OPENAI API for GPT 4o to Answer RD Exam Questions Using Zero-shot and CoT Promptings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai_api\n",
    "import questions_mysql\n",
    "import time\n",
    "\n",
    "api = openai_api.OpenAIAPI()\n",
    "qsql = questions_mysql.QuestionsMysql()\n",
    "# Connect to RD Exam Questions\n",
    "question_dict = qsql.get_rd_questions()\n",
    "\n",
    "# To run 5 rounds \n",
    "for i in range(1, 6):  \n",
    "    file_name = f'claude_exp{i}.txt'\n",
    "    with open(file_name, 'w') as file:\n",
    "        pass\n",
    "    \n",
    "    response = \"\"\n",
    "\n",
    "    # Starts the timer\n",
    "    start = time.time()\n",
    "\n",
    "    # Prompt the questions in a batch of 1, you can adjust the question number in each batch \n",
    "    for startIndex in range (1, len(question_dict) + 1, 1):\n",
    "        # Read what previous response we got from the LLMs \n",
    "        with open(file_name, 'r') as file:\n",
    "            content = file.read()\n",
    "        \n",
    "        # To use the zero-shot prompting instruction with the question\n",
    "        prompt_str = qsql.get_no_explain_prompt_string(question_dict, startIndex, 1)\n",
    "        # To use the CoT prompting instruction with the question\n",
    "        # prompt_str = qsql.get_cot_prompt_string(question_dict, startIndex, 1)\n",
    "\n",
    "        # Use the GPT 4o model and set temperature to 0. \n",
    "        response = api.ask_chatgpt(prompt_str, \"gpt-4o\", 0)\n",
    "\n",
    "        # Save the response to each question to the file\n",
    "        with open(file_name, 'w') as file:\n",
    "            file.write(content + prompt_str + \"\\n\" + response + \"\\n\\n\\n\")\n",
    "\n",
    "        end = time.time()\n",
    "        length = end - start # Calculate the time used for a round\n",
    "        print(\"Round\", i, \"took\", length, \"seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Amazon BedRock API for Claude 3.5 - Sonnet to Answer RD Exam Questions Using Zero-shot and CoT Promptings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anthropic_bedrock_api\n",
    "import questions_mysql\n",
    "import time\n",
    "\n",
    "\n",
    "api = anthropic_bedrock_api.AnthropicBedRockAPI()\n",
    "qsql = questions_mysql.QuestionsMysql()\n",
    "# Connect to RD Exam Questions\n",
    "question_dict = qsql.get_rd_questions()\n",
    "\n",
    "# To run 5 rounds \n",
    "for i in range(1, 6):  \n",
    "    file_name = f'claude_exp{i}.txt'\n",
    "    with open(file_name, 'w') as file:\n",
    "        pass\n",
    "    \n",
    "    response = \"\"\n",
    "\n",
    "    # Starts the timer\n",
    "    start = time.time()\n",
    "\n",
    "    # Prompt the questions in a batch of 1, you can adjust the question number in each batch \n",
    "    for startIndex in range (1, len(question_dict) + 1, 1):\n",
    "        # Read what previous response we got from the LLMs \n",
    "        with open(file_name, 'r') as file:\n",
    "            content = file.read()\n",
    "        \n",
    "        # To use the zero-shot prompting instruction with the question\n",
    "        prompt_str = qsql.get_no_explain_prompt_string(question_dict, startIndex, 1)\n",
    "        # To use the CoT prompting instruction with the question\n",
    "        # prompt_str = qsql.get_cot_prompt_string(question_dict, startIndex, 1)\n",
    "\n",
    "        # Use the Claude 3.5 - Sonnet model and set temperature to 0. \n",
    "        response = api.ask_claude(prompt_str, \"anthropic.claude-3-5-sonnet-20240620-v1:0\", 0)\n",
    "\n",
    "        # Save the response to each question to the file\n",
    "        with open(file_name, 'w') as file:\n",
    "            file.write(content + prompt_str + \"\\n\" + response + \"\\n\\n\\n\")\n",
    "\n",
    "        end = time.time()\n",
    "        length = end - start # Calculate the time used for a round\n",
    "        print(\"Round\", i, \"took\", length, \"seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Gemini API for Gemini 1.5 Pro to Answer RD Exam Questions Using Zero-shot and CoT Promptings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gemini_api\n",
    "import questions_mysql\n",
    "import time\n",
    "\n",
    "api = gemini_api.GeminiAIAPI()\n",
    "qsql = questions_mysql.QuestionsMysql()\n",
    "# Connect to RD Exam Questions\n",
    "question_dict = qsql.get_rd_questions()\n",
    "\n",
    "# To run 5 rounds \n",
    "for i in range(1, 6):  \n",
    "    file_name = f'gemini_exp{i}.txt'\n",
    "    with open(file_name, 'w') as file:\n",
    "        pass\n",
    "    \n",
    "    response = \"\"\n",
    "\n",
    "    # Starts the timer\n",
    "    start = time.time()\n",
    "\n",
    "    # Prompt the questions in a batch of 1, you can adjust the question number in each batch \n",
    "    for startIndex in range (1, len(question_dict) + 1, 1):\n",
    "        # Read what previous response we got from the LLMs \n",
    "        with open(file_name, 'r') as file:\n",
    "            content = file.read()\n",
    "        \n",
    "        # To use the zero-shot prompting instruction with the question\n",
    "        prompt_str = qsql.get_no_explain_prompt_string(question_dict, startIndex, 1)\n",
    "        # To use the CoT prompting instruction with the question\n",
    "        # prompt_str = qsql.get_cot_prompt_string(question_dict, startIndex, 1)\n",
    "\n",
    "        # Use the Gemini 1.5 Pro model and set temperature to 0. \n",
    "        response = api.ask_gemini(prompt_str, 'gemini-1.5-pro', 0)\n",
    "\n",
    "        # Save the response to each question to the file\n",
    "        with open(file_name, 'w') as file:\n",
    "            file.write(content + prompt_str + \"\\n\" + response + \"\\n\\n\\n\")\n",
    "\n",
    "        end = time.time()\n",
    "        length = end - start # Calculate the time used for a round\n",
    "        print(\"Round\", i, \"took\", length, \"seconds.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to LLMs to Ask RD Exam Questions using RAG Prompting\n",
    "### Step 1: Extract Chunks from pdfs\n",
    "You need to add divid your pdf contents to chunks and put them into a csv file first and then run the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from embedding import TitanEmbeddings\n",
    "\n",
    "# Load the knowledge dataframe (chunks)\n",
    "file_path = 'xxxx.csv'\n",
    "df_knowledge = pd.read_csv(file_path)\n",
    "\n",
    "# Check if 'chunk_embedding' column exists; if not, create it\n",
    "if 'chunk_embedding' not in df_knowledge.columns:\n",
    "    df_knowledge['chunk_embedding'] = None\n",
    "\n",
    "# Initialize the embedding model\n",
    "titan_embeddings_v2 = TitanEmbeddings(model_id=\"amazon.titan-embed-text-v2:0\")\n",
    "\n",
    "# Define parameters\n",
    "dimensions = 1024\n",
    "normalize = True\n",
    "\n",
    "# Process each chunk\n",
    "for i, row in df_knowledge.iterrows():\n",
    "    # Check if the chunk embedding is already computed\n",
    "    if pd.notna(row['chunk_embedding']):\n",
    "        continue\n",
    "    \n",
    "    chunk = row['chunk']\n",
    "    input_text = chunk\n",
    "    \n",
    "    # Obtain the embedding of the chunk\n",
    "    chunk_embedding = titan_embeddings_v2(input_text, dimensions, normalize)\n",
    "    \n",
    "    # Save the embedding to the dataframe\n",
    "    df_knowledge.at[i, 'chunk_embedding'] = chunk_embedding\n",
    "    \n",
    "    # Save progress after processing each chunk\n",
    "    df_knowledge.to_csv(file_path, index=False)\n",
    "    print(f\"Processed and saved chunk {i + 1}/{len(df_knowledge)}\")\n",
    "\n",
    "print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Find Similar Chunks\n",
    "Now you have the chunks and their embeddings, you can use the code below to find the top 10 similar chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from questions_mysql import QuestionsMysql\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from embedding import TitanEmbeddings\n",
    "\n",
    "\n",
    "def find_most_similar_chunks(\n",
    "        query_embedding: list,\n",
    "        df: pd.DataFrame,\n",
    "        number_of_chunks: int = 10) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Search for the most similar chunks\n",
    "    \n",
    "    Args:\n",
    "        query_embedding (list): The embedding of the question.\n",
    "        df (pd.DataFrame): The dataframe including the chunks and their embeddings.\n",
    "        number_of_chunks (int): Number of smilar chunks to be selected.\n",
    "    \n",
    "    Returns:\n",
    "        similar_chunks (np.ndarray): The array of N most similar chunks.\n",
    "    \"\"\"\n",
    "    #print(type(query_embedding))\n",
    "    # Convert the 'chunk_embedding' column to an array of arrays\n",
    "    chunk_embeddings = df['chunk_embedding'].apply(ast.literal_eval).tolist()\n",
    "    chunk_embeddings = np.array(chunk_embeddings)\n",
    "    \n",
    "    cosine_scores = cosine_similarity([query_embedding], chunk_embeddings)[0]\n",
    "    cosine_scores_sorted_indices = np.argsort(cosine_scores)[::-1]\n",
    "    print(cosine_scores[cosine_scores_sorted_indices])\n",
    "    sorted_chunks_text = df['chunk'].iloc[cosine_scores_sorted_indices]\n",
    "    similar_chunks = sorted_chunks_text.head(number_of_chunks)\n",
    "    return similar_chunks.values\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Read question from a file\n",
    "    qsql = QuestionsMysql()\n",
    "    # Connect to RD Exam Questions\n",
    "    question_dict = qsql.get_RD_questions()\n",
    "\n",
    "    # Load knowledge dataframe (chunks)\n",
    "    FILE_PATH = 'xxxx.csv'\n",
    "    columns_to_read = ['chunk', 'chunk_embedding']\n",
    "    df_knowledge = pd.read_csv(FILE_PATH, usecols=columns_to_read)\n",
    "\n",
    "    # Obtain the embedding of the question using the embedding model\n",
    "    dimensions = 1024\n",
    "    normalize = True\n",
    "\n",
    "    titan_embeddings_v2 = TitanEmbeddings(model_id=\"amazon.titan-embed-text-v2:0\")\n",
    "   \n",
    "    results_df = pd.DataFrame(columns=['question_id', 'top_10_similar_chunks'])\n",
    "\n",
    "    data = []\n",
    "    for startIndex in range (1, len(question_dict) + 1, 1):\n",
    "        query = question_dict[startIndex]['question'] + question_dict[startIndex]['choices']\n",
    "\n",
    "        input_text = query\n",
    "        query_embeddings = titan_embeddings_v2(input_text, dimensions, normalize)\n",
    "\n",
    "        # Cosine similarity\n",
    "        selected_chunks = find_most_similar_chunks(query_embeddings, df_knowledge)\n",
    "        # Covert the selected chunks to string to be added to the prompt\n",
    "        selected_chunks_str = np.array2string(selected_chunks, separator=', ')\n",
    "        data.append({'question_id': startIndex, 'top_10_similar_chunks': selected_chunks_str})\n",
    "        print(f\"Processed {startIndex}/{len(question_dict)}\")\n",
    "\n",
    "    # Create a DataFrame from the new data\n",
    "    results_df = pd.DataFrame(data)\n",
    "\n",
    "    # Save the DataFrame to a new CSV file\n",
    "    new_file_path = 'new_xxxxx.csv'\n",
    "    results_df.to_csv(new_file_path, index=False)\n",
    "    print(\"Completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Send the Similar Chunks together with the Questions to LLMs\n",
    "\n",
    "#### Claude 3.5 - Sonnet with RAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import anthropic_bedrock_api\n",
    "import time\n",
    "\n",
    "from questions_mysql import QuestionsMysql\n",
    "\n",
    "    \n",
    "qsql = QuestionsMysql()\n",
    "# Connect to RD Exam Questions\n",
    "question_dict = qsql.get_rd_questions()\n",
    "\n",
    "api = anthropic_bedrock_api.AnthropicBedRockAPI()\n",
    "\n",
    "# Get the extracted similar chunks\n",
    "FILE_PATH = 'xxxx.csv'\n",
    "df = pd.read_csv(FILE_PATH)\n",
    "similar_chunks_list = []\n",
    "for index, row in df.iterrows():\n",
    "    similar_chunks_list.append(row['top_10_similar_chunks'])\n",
    "\n",
    "# To run 5 rounds\n",
    "for i in range(1, 6):  \n",
    "    file_name = f'claude_3.5_sonnet_rag_exp{i}.txt'\n",
    "    with open(file_name, 'w') as file:\n",
    "        pass\n",
    "\n",
    "    # Starts the timer\n",
    "    start = time.time()\n",
    "    response = \"\\n\"\n",
    "    for startIndex in range (1, len(question_dict) + 1, 1):\n",
    "        selected_chunk_str = similar_chunks_list[startIndex - 1]\n",
    "\n",
    "        with open(file_name, 'r') as file:\n",
    "            content = file.read()\n",
    "\n",
    "        prompt_str = qsql.get_rag_prompt_string(question_dict, startIndex, 1, selected_chunk_str)\n",
    "\n",
    "        response = api.ask_claude(prompt_str, \"anthropic.claude-3-5-sonnet-20240620-v1:0\", 0) \n",
    "        response += \"\\n\"\n",
    "\n",
    "        # Saves the response of each question to a file\n",
    "        with open(file_name, 'w') as file:\n",
    "            file.write(content + prompt_str + \"\\n\" + response + \"\\n\\n\\n\")\n",
    "        \n",
    "    end = time.time()\n",
    "    length = end - start\n",
    "    print(\"Round\", i, \"took\", length, \"seconds.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gemini 1.5 Pro with RAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gemini_api\n",
    "import time\n",
    "\n",
    "from questions_mysql import QuestionsMysql\n",
    "\n",
    "    \n",
    "qsql = QuestionsMysql()\n",
    "# Connect to RD Exam Questions\n",
    "question_dict = qsql.get_rd_questions()\n",
    "\n",
    "api = gemini_api.GeminiAIAPI()\n",
    "\n",
    "# Get the extracted similar chunks\n",
    "FILE_PATH = 'xxxx.csv'\n",
    "df = pd.read_csv(FILE_PATH)\n",
    "similar_chunks_list = []\n",
    "for index, row in df.iterrows():\n",
    "    similar_chunks_list.append(row['top_10_similar_chunks'])\n",
    "\n",
    "# To run 5 rounds\n",
    "for i in range(1, 6):  \n",
    "    file_name = f'gemini_1.5_pro_rag_exp{i}.txt'\n",
    "    with open(file_name, 'w') as file:\n",
    "        pass\n",
    "\n",
    "    # Starts the timer\n",
    "    start = time.time()\n",
    "    response = \"\\n\"\n",
    "    for startIndex in range (1, len(question_dict) + 1, 1):\n",
    "        selected_chunk_str = similar_chunks_list[startIndex - 1]\n",
    "\n",
    "        with open(file_name, 'r') as file:\n",
    "            content = file.read()\n",
    "\n",
    "        prompt_str = qsql.get_rag_prompt_string(question_dict, startIndex, 1, selected_chunk_str)\n",
    "\n",
    "        response = api.ask_gemini(prompt_str, 'gemini-1.5-pro', 0) \n",
    "        response += \"\\n\"\n",
    "\n",
    "        # Saves the response of each question to a file\n",
    "        with open(file_name, 'w') as file:\n",
    "            file.write(content + prompt_str + \"\\n\" + response + \"\\n\\n\\n\")\n",
    "        \n",
    "    end = time.time()\n",
    "    length = end - start\n",
    "    print(\"Round\", i, \"took\", length, \"seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPT 4o with RAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai_api\n",
    "import time\n",
    "\n",
    "from questions_mysql import QuestionsMysql\n",
    "\n",
    "    \n",
    "qsql = QuestionsMysql()\n",
    "# Connect to RD Exam Questions\n",
    "question_dict = qsql.get_rd_questions()\n",
    "\n",
    "api = openai_api.OpenAIAPI()\n",
    "\n",
    "# Get the extracted similar chunks\n",
    "FILE_PATH = 'xxxx.csv'\n",
    "df = pd.read_csv(FILE_PATH)\n",
    "similar_chunks_list = []\n",
    "for index, row in df.iterrows():\n",
    "    similar_chunks_list.append(row['top_10_similar_chunks'])\n",
    "\n",
    "# To run 5 rounds\n",
    "for i in range(1, 6):  \n",
    "    file_name = f'gpt_4o_rag_exp{i}.txt'\n",
    "    with open(file_name, 'w') as file:\n",
    "        pass\n",
    "\n",
    "    # Starts the timer\n",
    "    start = time.time()\n",
    "    response = \"\\n\"\n",
    "    for startIndex in range (1, len(question_dict) + 1, 1):\n",
    "        selected_chunk_str = similar_chunks_list[startIndex - 1]\n",
    "\n",
    "        with open(file_name, 'r') as file:\n",
    "            content = file.read()\n",
    "\n",
    "        prompt_str = qsql.get_rag_prompt_string(question_dict, startIndex, 1, selected_chunk_str)\n",
    "        print(\"Prompt: \\n\" + prompt_str)\n",
    "\n",
    "        response = api.ask_chatgpt(prompt_str, \"gpt-4o\", 0)\n",
    "        response += \"\\n\"\n",
    "\n",
    "        # Saves the response of each question to a file\n",
    "        with open(file_name, 'w') as file:\n",
    "            file.write(content + prompt_str + \"\\n\" + response + \"\\n\\n\\n\")\n",
    "        \n",
    "    end = time.time()\n",
    "    length = end - start\n",
    "    print(\"Round\", i, \"took\", length, \"seconds.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Results of the Questions from the Response\n",
    "Some of the answers in the responses may not follow the xmL tag format. The code below will also print out the answers that do not match the xml tag format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import questions_mysql\n",
    "import re\n",
    "\n",
    "# Get the correct answers\n",
    "qsql = questions_mysql.QuestionsMysql()\n",
    "question_dict = qsql.get_rd_questions()\n",
    "\n",
    "# Get the LLM's response from the txt file\n",
    "with open('filename.txt', 'r') as file:\n",
    "        content = file.read()\n",
    "\n",
    "# Get the answer list and score\n",
    "choices = qsql.get_answer_xml(content)\n",
    "if len(choices) == 1050:\n",
    "    answers = '\\n'.join(choices)\n",
    "    score4 = qsql.get_score_xml(content, question_dict)\n",
    "    print(score4)\n",
    "\n",
    "    # Save answer list and score to the txt file\n",
    "    with open('filename.txt', 'w') as file:\n",
    "        file.write(content + \"Answer List: \\n\" + answers + \"\\n\" + score4)\n",
    "else:\n",
    "    # Find the missed answer\n",
    "    all_tags_pattern = r\"<answer>[^<]*</answer>\"\n",
    "    '''\n",
    "    all_tags_pattern = r\"[^<]*</answer>Instruction\"\n",
    "    \n",
    "    all_tags = re.findall(all_tags_pattern, content)\n",
    "    for tag in all_tags:\n",
    "        print(tag)\n",
    "    '''\n",
    "    # Specific pattern to match\n",
    "    specific_pattern = r\"<answer>([a-dA-D]|NaN)(?:\\.[^<]*)?</answer>\"\n",
    "\n",
    "    # Find all answer tags\n",
    "    all_tags = re.findall(all_tags_pattern, content)\n",
    "\n",
    "    # Filter out those that match the specific pattern\n",
    "    non_matching_tags = [tag for tag in all_tags if not re.match(specific_pattern, tag)]\n",
    "\n",
    "    # Print non-matching tags\n",
    "    for tag in non_matching_tags:\n",
    "        if tag!= \"<answer></answer>\":\n",
    "            print(tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the questions's answer may not be provided by the LLM, using the code below to find the ones missing an answer. There should be two \\<answer> and two \\</answer> for each question. The missing situation may be the second \\<answer> was missed, the second \\</answer> was missed, or both were missed. Please adjust the code below as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'xxxx'  # Replace with your file name\n",
    "with open(filename, 'r') as file:\n",
    "    content = file.read()\n",
    "\n",
    "questions = content.split('Instructions:')\n",
    "missing_answers = []\n",
    "\n",
    "for i, question in enumerate(questions[1:], start=1):  # start=1 to skip the first empty split\n",
    "    #if '</answer>' not in question:\n",
    "        #missing_answers.append(i)\n",
    "    answer_count = question.count('</answer>')\n",
    "    if answer_count == 1:\n",
    "        missing_answers.append(i)\n",
    "\n",
    "if missing_answers:\n",
    "    print(f'The following questions are missing answers: {missing_answers}')\n",
    "else:\n",
    "    print('All questions have answers.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
